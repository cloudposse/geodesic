##
## Master Helmfile by Cloud Posse, LLC <hello@cloudposse.com>
##

#
# Examples:
#
#   Install all charts that belong in `kube-system` except for `chart-repo`
#
#     helmfile --selector namespace=kube-system,chart!=chart-repo sync
#
#   Install all default charts
#
#     helmfile --selector default=true sync
#
# References:
#   - https://github.com/roboll/helmfile
#

helmDefaults:
  args:
    - "--wait"
    - "--recreate-pods"
    - "--timeout=600"
    - "--force"
    - "--reset-values"

repositories:
# Stable repo of official helm charts
- name: "stable"
  url: "https://kubernetes-charts.storage.googleapis.com"

# Incubator repo of official helm charts
- name: "incubator"
  url: "https://kubernetes-charts-incubator.storage.googleapis.com"

# Cloud Posse incubator repo of helm charts
- name: "cloudposse-incubator"
  url: "https://charts.cloudposse.com/incubator/"

# CoreOS Stable helm charts
- name: "coreos-stable"
  url: "https://s3-eu-west-1.amazonaws.com/coreos-charts/stable"

releases:

################################################################################
## Chart Museum ################################################################
################################################################################

- name: "charts"
  namespace: "kube-system"
  labels:
    chart: "chartmuseum"
    component: "platform"
    namespace: "kube-system"
    vendor: "kubernetes-helm"
    default: "true"
  chart: "stable/chartmuseum"
  version: "1.4.0"
  values:
    - "values/chartmuseum.yaml"
  set:
    - name: "replicaCount"
      value: "1"

    # disable all routes prefixed with /api
    - name: "env.open.DISABLE_API"
      value: "true"

    # show debug messages
    - name: "env.open.DEBUG"
      value: '{{ env "CHARTMUSEUM_DEBUG" | default "false" }}'

    # allow chart versions to be re-uploaded
    - name: "env.open.ALLOW_OVERWRITE"
      value: "false"

    # use amazon s3 storage as backend
    - name: "env.open.STORAGE"
      value: "amazon"

    ### Required: CHARTMUSEUM_STORAGE_AMAZON_BUCKET;
    - name: "env.open.STORAGE_AMAZON_BUCKET"
      value: '{{ env "CHARTMUSEUM_STORAGE_AMAZON_BUCKET" }}'

    ### Required: CHARTMUSEUM_STORAGE_AMAZON_PREFIX; e.g. /
    - name: "env.open.STORAGE_AMAZON_PREFIX"
      value: '{{ env "CHARTMUSEUM_STORAGE_AMAZON_PREFIX" }}'

    ### Required: CHARTMUSEUM_STORAGE_AMAZON_REGION; e.g. us-west-2
    - name: "env.open.STORAGE_AMAZON_REGION"
      value: '{{ env "CHARTMUSEUM_STORAGE_AMAZON_REGION" }}'

    ### Required: CHARTMUSEUM_BASIC_AUTH_USER; e.g. server
    - name: "env.secret.BASIC_AUTH_USER"
      value: '{{ env "CHARTMUSEUM_BASIC_AUTH_USER" }}'

    ### Required: CHARTMUSEUM_BASIC_AUTH_PASS; e.g. 15041434-3DC2-42F8-9358-F8AED8780A66
    - name: "env.secret.BASIC_AUTH_PASS"
      value: '{{ env "CHARTMUSEUM_BASIC_AUTH_PASS" }}'

    ### Required: CHARTMUSEUM_IAM_ROLE;
    - name: "replica.annotations.iam\\.amazonaws\\.com/role"
      value: '{{ env "CHARTMUSEUM_IAM_ROLE" }}'

    ## Resources
    - name: "resources.limits.cpu"
      value: "100m"

    - name: "resources.limits.memory"
      value: "512Mi"

    - name: "requests.cpu"
      value: "5m"

    - name: "requests.memory"
      value: "256Mi"

    ## Ingress
    - name: "ingress.enabled"
      value: "true"

    - name: "ingress.annotations.kubernetes\\.io/ingress\\.class"
      value: "nginx"

    # FIXME: this is blocked by https://github.com/roboll/helmfile/issues/119
    #- name: "ingress.annotations.kubernetes\\.io/tls-acme"
    #  value: "true"

    ### Required: CHARTMUSEUM_HOSTNAME; e.g. e.g. charts.us-west-2.staging.cloudposse.co
    - name: "ingress.annotations.external-dns\\.alpha\\.kubernetes\\.io/hostname"
      value: '{{ env "CHARTMUSEUM_HOSTNAME" }}'

    ### Required: CHARTMUSEUM_INGRESS; e.g. ingress.us-west-2.staging.cloudposse.co
    - name: "ingress.annotations.external-dns\\.alpha\\.kubernetes\\.io/target"
      value: '{{ env "CHARTMUSEUM_INGRESS" }}'

    # DNS TTL for CHARTMUSEUM_HOSTNAME; e.g. 60
    # FIXME: this is blocked by https://github.com/roboll/helmfile/issues/119
    #- name: "ingress.annotations.external-dns\\.alpha\\.kubernetes\\.io/ttl"
    #  value: "60"

    ### Required: CHARTMUSEUM_HOSTNAME; e.g. charts.us-west-2.staging.cloudposse.co
    - name: 'ingress.hosts.{{ env "CHARTMUSEUM_HOSTNAME" | replace "." "\\." }}[0]'
      value: "/charts"

    ### Required: CHARTMUSEUM_HOSTNAME; e.g. charts.us-west-2.staging.cloudposse.co
    - name: 'ingress.hosts.{{ env "CHARTMUSEUM_HOSTNAME" | replace "." "\\." }}[1]'
      value: "/index.yaml"

    ### Optional: CHARTMUSEUM_SECRET_NAME; e.g. chartmuseum-server-tls
    - name: "ingress.tls[0].secretName"
      value: '{{ env "CHARTMUSEUM_SECRET_NAME" | default "chartmuseum-server-tls" }}'

    ### Required: CHARTMUSEUM_HOSTNAME; e.g. charts.us-west-2.staging.cloudposse.co
    - name: "ingress.tls[0].hosts[0]"
      value: '{{ env "CHARTMUSEUM_HOSTNAME" }}'


################################################################################
## Chart Museum API ############################################################
################################################################################

- name: "charts-api"
  namespace: "kube-system"
  labels:
    chart: "chartmuseum"
    component: "platform"
    namespace: "kube-system"
    vendor: "kubernetes-helm"
    default: "true"
  chart: "stable/chartmuseum"
  version: "1.4.0"
  values:
    - "values/chartmuseum.yaml"
  set:
    - name: "replicaCount"
      value: "1"

    # disable all routes prefixed with /api
    - name: "env.open.DISABLE_API"
      value: "false"

    # allow chart versions to be re-uploaded
    - name: "env.open.ALLOW_OVERWRITE"
      value: "true"

    # show debug messages
    - name: "env.open.DEBUG"
      value: '{{ env "CHARTMUSEUM_DEBUG" | default "false" }}'

    # use amazon s3 storage as backend
    - name: "env.open.STORAGE"
      value: "amazon"

    ### Required: CHARTMUSEUM_STORAGE_AMAZON_BUCKET;
    - name: "env.open.STORAGE_AMAZON_BUCKET"
      value: '{{ env "CHARTMUSEUM_STORAGE_AMAZON_BUCKET" }}'

    ### Required: CHARTMUSEUM_STORAGE_AMAZON_PREFIX; e.g. /
    - name: "env.open.STORAGE_AMAZON_PREFIX"
      value: '{{ env "CHARTMUSEUM_STORAGE_AMAZON_PREFIX" }}'

    ### Required: CHARTMUSEUM_STORAGE_AMAZON_REGION; e.g. us-west-2
    - name: "env.open.STORAGE_AMAZON_REGION"
      value: '{{ env "CHARTMUSEUM_STORAGE_AMAZON_REGION" }}'

    ### Required: CHARTMUSEUM_BASIC_AUTH_USER; e.g. server
    - name: "env.secret.BASIC_AUTH_USER"
      value: '{{ env "CHARTMUSEUM_API_BASIC_AUTH_USER" }}'

    ### Required: CHARTMUSEUM_BASIC_AUTH_PASS; e.g. 15041434-3DC2-42F8-9358-F8AED8780A66
    - name: "env.secret.BASIC_AUTH_PASS"
      value: '{{ env "CHARTMUSEUM_API_BASIC_AUTH_PASS" }}'

    ### Required: CHARTMUSEUM_IAM_ROLE;
    - name: "replica.annotations.iam\\.amazonaws\\.com/role"
      value: '{{ env "CHARTMUSEUM_IAM_ROLE" }}'

    ## Resources
    - name: "resources.limits.cpu"
      value: "100m"

    - name: "resources.limits.memory"
      value: "512Mi"

    - name: "requests.cpu"
      value: "5m"

    - name: "requests.memory"
      value: "256Mi"

    ## Ingress
    - name: "ingress.enabled"
      value: "true"

    - name: "ingress.annotations.kubernetes\\.io/ingress\\.class"
      value: "nginx"

    # FIXME: this is blocked by https://github.com/roboll/helmfile/issues/119
    #- name: "ingress.annotations.kubernetes\\.io/tls-acme"
    #  value: "true"

    ### Required: CHARTMUSEUM_INGRESS; e.g. ingress.us-west-2.staging.cloudposse.co
    - name: "ingress.annotations.external-dns\\.alpha\\.kubernetes\\.io/target"
      value: '{{ env "CHARTMUSEUM_INGRESS" }}'

    # DNS TTL for CHARTMUSEUM_API_HOSTNAME; e.g. 60
    # FIXME: this is blocked by https://github.com/roboll/helmfile/issues/119
    #- name: "ingress.annotations.external-dns\\.alpha\\.kubernetes\\.io/ttl"
    #  value: "60"

    ### Required: CHARTMUSEUM_API_HOSTNAME; e.g. api.charts.us-west-2.staging.cloudposse.co
    - name: 'ingress.hosts.{{ env "CHARTMUSEUM_API_HOSTNAME" | replace "." "\\." }}[0]'
      value: "/api"

    ### Optional: CHARTMUSEUM_API_SECRET_NAME; e.g. chartmuseum-api-server-tls
    - name: "ingress.tls[0].secretName"
      value: '{{ env "CHARTMUSEUM_API_SECRET_NAME" | default "chartmuseum-api-server-tls" }}'

    ### Required: CHARTMUSEUM_API_HOSTNAME; e.g. api.charts.us-west-2.staging.cloudposse.co
    - name: "ingress.tls[0].hosts[0]"
      value: '{{ env "CHARTMUSEUM_API_HOSTNAME" }}'

################################################################################
## External DNS ################################################################
################################################################################

#
# References:
#   - https://github.com/kubernetes/charts/blob/master/stable/external-dns/values.yaml
#
- name: "dns"
  namespace: "kube-system"
  labels:
    chart: "external-dns"
    component: "ingress"
    namespace: "kube-system"
    vendor: "kubernetes-incubator"
    default: "true"
  chart: "stable/external-dns"
  version: "0.5.4"
  set:
    - name: "extraEnv.EXTERNAL_DNS_SOURCE"
      value: "service\ningress"

    ### Required: EXTERNAL_DNS_TXT_OWNER_ID; e.g. us-west-2.staging.cloudposse.co
    - name: "txtOwnerId"
      value: '{{ env "EXTERNAL_DNS_TXT_OWNER_ID" }}'

    ### Required: EXTERNAL_DNS_TXT_PREFIX; e.g. 11591833-F9CE-407C-8519-35A947DB1D87-
    - name: "txtPrefix"
      value: '{{ env "EXTERNAL_DNS_TXT_PREFIX" }}'

    - name: "publishInternalServices"
      value: "true"

    - name: "provider"
      value: "aws"

    ### Required: EXTERNAL_DNS_IAM_ROLE; e.g. cp-staging-external-dns
    - name: "podAnnotations.iam\\.amazonaws\\.com/role"
      value: '{{ env "EXTERNAL_DNS_IAM_ROLE" }}'

    ## Resources
    - name: "resources.limits.cpu"
      value: "200m"

    - name: "resources.limits.memory"
      value: "256Mi"

    - name: "resources.requests.cpu"
      value: "100m"

    - name: "resources.requests.memory"
      value: "128Mi"

################################################################################
## Kube Lego - Automatic Let's Encrypt for Ingress  ############################
################################################################################

#
# References:
#   - https://github.com/cloudposse/charts/blob/master/incubator/kube-lego/values.yaml
#
- name: "tls"
  namespace: "kube-system"
  labels:
    chart: "kube-lego"
    component: "ingress"
    namespace: "kube-system"
    vendor: "jetstack"
    default: "true"
  chart: "cloudposse-incubator/kube-lego"
  version: "0.1.2"
  set:
    ### Optional: KUBE_LEGO_REPLICA_COUNT; e.g. 1
    - name: "replicaCount"
      value: '{{ env "KUBE_LEGO_REPLICA_COUNT" | default "1" }}'

    ### Optional: KUBE_LEGO_DEBUG; e.g. false
    - name: "debug"
      value: '{{ env "KUBE_LEGO_DEBUG" | default "false" }}'

    ## Image
    - name: "image.repository"
      value: "jetstack/kube-lego"

    ### Optional: KUBE_LEGO_IMAGE_TAG; e.g. 0.1.2
    - name: "image.tag"
      value: '{{ env "KUBE_LEGO_IMAGE_TAG" | default "0.1.5" }}'

    - name: "image.pullPolicy"
      value: "IfNotPresent"

    ## Lego Settings
    ### Required: KUBE_LEGO_EMAIL; e.g. ops@cloudposse.co
    - name: "lego.email"
      value: '{{ env "KUBE_LEGO_EMAIL" }}'

    ### Optional: KUBE_LEGO_PROD; e.g. true
    - name: "lego.prod"
      value: '{{ env "KUBE_LEGO_PROD" | default "true" }}'

    ## Pod Settings
    - name: "pod.internalPort"
      value: "8080"

    ## Resources
    - name: "resources.limits.cpu"
      value: "200m"

    - name: "resources.limits.memory"
      value: "256Mi"

    - name: "resources.requests.cpu"
      value: "50m"

    - name: "resources.requests.memory"
      value: "128Mi"

################################################################################
## Kube2IAM - AWS Assumed Roles for Pods #######################################
################################################################################

#
# References:
#   - https://github.com/kubernetes/charts/blob/master/stable/kube2iam/values.yaml
#
- name: "iam"
  namespace: "kube-system"
  labels:
    chart: "kube2iam"
    component: "iam"
    namespace: "kube-system"
    vendor: "jtblin"
    default: "false"
  chart: "stable/kube2iam"
  version: "0.8.5"
  set:
    - name: "tolerations[0].key"
      value: "node-role.kubernetes.io/master"

    - name: "tolerations[0].effect"
      value: "NoSchedule"

    ### Required: AWS_REGION; e.g. us-west-2
    - name: "aws.region"
      value: '{{ env "AWS_REGION" }}'

    - name: "extraArgs.auto-discover-base-arn"
      value: "true"

    - name: "host.iptables"
      value: "true"

    - name: "host.interface"
      value: "cali+"

    - name: "resources.limits.cpu"
      value: "200m"

    - name: "resources.limits.memory"
      value: "256Mi"

    - name: "resources.requests.cpu"
      value: "50m"

    - name: "resources.requests.memory"
      value: "128Mi"

################################################################################
## kiam - AWS Assumed Roles for Pods #######################################
################################################################################

#
# References:
#   - https://github.com/kubernetes/charts/blob/master/stable/kiam/values.yaml

# The release name must be "kiam" for chart to work properly with TLS/PKI certs
- name: "kiam"
  namespace: "kube-system"
  labels:
    chart: "kiam"
    component: "iam"
    namespace: "kube-system"
    vendor: "uswitch"
    default: "true"
  chart: "stable/kiam"
  version: "1.0.0"
  values:
    - rbac:
        create: {{ env "KIAM_RBAC_CREATE" | default "false" }}
      agent:
        gatewayTimeoutCreation: "5s"
        host:
          iptables: "true"
          interface: "cali+"
        nodeSelector:
          kubernetes.io/role: "node"
        tolerations:
          - operator: "Exists"
        tlsFiles:
          ### Required: KIAM_AGENT_TLS_CA; e.g. base64-encoded ca.pem
          ca: '{{ env "KIAM_AGENT_TLS_CA" }}'
          ### Required: KIAM_AGENT_TLS_CERT; e.g. base64-encoded agent.pem
          cert: '{{ env "KIAM_AGENT_TLS_CERT" }}'
          ### Required: KIAM_AGENT_TLS_KEY; e.g. base64-encoded agent-key.pem
          key: '{{ env "KIAM_AGENT_TLS_KEY" }}'
      server:
        gatewayTimeoutCreation: "5s"
        nodeSelector:
          kubernetes.io/role: "master"
        tolerations:
          - key: "node-role.kubernetes.io/master"
            effect: "NoSchedule"
            operator: "Exists"
        extraHostPathMounts:
          - name: "ssl-certs"
            mountPath: "/etc/ssl/certs"
            hostPath: '{{ env "KIAM_HOST_CERT_PATH" | default "/etc/ssl/certs" }}'
            readOnly: true
        tlsFiles:
          ### Required: KIAM_AGENT_TLS_CA; e.g. base64-encoded ca.pem
          ca: '{{ env "KIAM_SERVER_TLS_CA" }}'
          ### Required: KIAM_SERVER_TLS_CERT; e.g. base64-encoded server.pem
          cert: '{{ env "KIAM_SERVER_TLS_CERT" }}'
          ### Required: KIAM_SERVER_TLS_KEY; e.g. base64-encoded server-key.pem
          key: '{{ env "KIAM_SERVER_TLS_KEY" }}'

################################################################################
## NGINX Ingress Controller ####################################################
################################################################################

#
# References:
#   - https://github.com/cloudposse/charts/blob/master/incubator/nginx-ingress/values.yaml
#
- name: "ingress"
  namespace: "kube-system"
  labels:
    chart: "nginx-ingress"
    component: "ingress"
    namespace: "kube-system"
    vendor: "kubernetes"
    default: "true"
  chart: "cloudposse-incubator/nginx-ingress"
  version: "0.1.7"
  values:
  - "values/nginx-ingress.yaml"
  set:
    ### Optional: NGINX_INGRESS_REPLICA_COUNT; e.g. 4
    - name: "replicaCount"
      value: '{{ env "NGINX_INGRESS_REPLICA_COUNT" | default "4" }}'

    - name: "image.repository"
      value: "quay.io/kubernetes-ingress-controller/nginx-ingress-controller"

    ### Optional: NGINX_INGRESS_IMAGE_TAG; e.g. 0.11.0
    - name: "image.tag"
      value: '{{ env "NGINX_INGRESS_IMAGE_TAG" | default "0.11.0" }}'

    - name: "image.pullPolicy"
      value: "IfNotPresent"

    - name: "resources.limits.cpu"
      value: "200m"

    - name: "resources.limits.memory"
      value: "256Mi"

    - name: "resources.requests.cpu"
      value: "50m"

    - name: "resources.requests.memory"
      value: "128Mi"

    ### Optional: NGINX_INGRESS_BACKEND_REPLICA_COUNT; e.g. 2
    - name: "nginx-default-backend.replicaCount"
      value: '{{ env "NGINX_INGRESS_BACKEND_REPLICA_COUNT" | default "2" }}'

    - name: "nginx-default-backend.resources.limits.cpu"
      value: "200m"

    - name: "nginx-default-backend.resources.limits.memory"
      value: "256Mi"

    - name: "nginx-default-backend.resources.requests.cpu"
      value: "50m"

    - name: "nginx-default-backend.resources.requests.memory"
      value: "128Mi"

    ### Required: NGINX_INGRESS_HOSTNAME; e.g. ingress.us-west-2.cloudposse.co
    - name: "service.annotations.external-dns\\.alpha\\.kubernetes\\.io/hostname"
      value: '{{ env "NGINX_INGRESS_HOSTNAME" }}'

    ### Optional: NGINX_INGRESS_TTL; e.g. 60
    # FIXME: this is blocked by https://github.com/roboll/helmfile/issues/119
    #- name: "service.annotations.external-dns\\.alpha\\.kubernetes\\.io/ttl"
    #  value: {{ env "NGINX_INGRESS_TTL" | default "60" }}


#######################################################################################
## prometheus-operator                                                               ##
## creates/configures/manages Prometheus clusters atop Kubernetes                    ##
#######################################################################################

#
# References:
#   - https://github.com/coreos/prometheus-operator/tree/master/helm/prometheus-operator
#   - https://github.com/coreos/prometheus-operator
#
- name: "prometheus-operator"
  namespace: "kube-system"
  labels:
    chart: "prometheus-operator"
    component: "monitoring"
    namespace: "kube-system"
    vendor: "coreos"
    default: "true"
  chart: "coreos-stable/prometheus-operator"
  version: "0.0.23"
  set:
    - name: "rbacEnable"
      value: "false"

    - name: "jobLabel"
      value: "prometheus-operator"

    - name: "image.repository"
      value: "quay.io/coreos/prometheus-operator"

    ### Optional: PROMETHEUS_OPERATOR_IMAGE_TAG; e.g. v0.17.0
    - name: "image.tag"
      value: '{{ env "PROMETHEUS_OPERATOR_IMAGE_TAG" | default "v0.17.0" }}'

    - name: "image.pullPolicy"
      value: "IfNotPresent"

    - name: "resources.limits.cpu"
      value: "10m"

    - name: "resources.limits.memory"
      value: "64Mi"

    - name: "resources.requests.cpu"
      value: "5m"

    - name: "resources.requests.memory"
      value: "32Mi"

    - name: "global.hyperkube.repository"
      value: "quay.io/coreos/hyperkube"

    ### Optional: PROMETHEUS_OPERATOR_GLOBAL_HYPERKUBE_IMAGE_TAG; e.g. v1.7.6_coreos.0
    - name: "global.hyperkube.tag"
      value: '{{ env "PROMETHEUS_OPERATOR_GLOBAL_HYPERKUBE_IMAGE_TAG" | default "v1.7.6_coreos.0" }}'

    - name: "global.hyperkube.pullPolicy"
      value: "IfNotPresent"

    - name: "prometheusConfigReloader.repository"
      value: "quay.io/coreos/prometheus-config-reloader"

    ### Optional: PROMETHEUS_OPERATOR_PROMETHEUS_CONFIG_RELOADER_IMAGE_TAG; e.g. v0.0.3
    - name: "prometheusConfigReloader.tag"
      value: '{{ env "PROMETHEUS_OPERATOR_PROMETHEUS_CONFIG_RELOADER_IMAGE_TAG" | default "v0.0.3" }}'

    - name: "configmapReload.repository"
      value: "quay.io/coreos/configmap-reload"

    ### Optional: PROMETHEUS_OPERATOR_CONFIGMAP_RELOAD_IMAGE_TAG; e.g. v0.0.1
    - name: "configmapReload.tag"
      value: '{{ env "PROMETHEUS_OPERATOR_CONFIGMAP_RELOAD_IMAGE_TAG" | default "v0.0.1" }}'

    ### If enabled, prometheus-operator will create a service for scraping kubelets
    - name: "kubeletService.enable"
      value: "true"

    - name: "kubeletService.namespace"
      value: "kube-system"

    - name: "kubeletService.name"
      value: "kubelet"


#######################################################################################
## kube-prometheus                                                                   ##
## Collects Kubernetes manifests, Grafana dashboards, and Prometheus rules           ##
## combined with documentation and scripts to provide single-command                 ##
## deployments of end-to-end Kubernetes cluster monitoring with Prometheus operator  ##
#######################################################################################

#
# References:
#   - https://github.com/coreos/prometheus-operator/tree/master/helm/kube-prometheus
#   - https://github.com/coreos/prometheus-operator/tree/master/contrib/kube-prometheus
#   - https://prometheus.io/docs/alerting/configuration
#   - https://medium.com/@timfpark/simple-kubernetes-cluster-monitoring-with-prometheus-and-grafana-dd27edb1641
#   - https://www.weave.works/blog/monitoring-kubernetes-infrastructure
#   - https://www.datadoghq.com/blog/how-to-collect-and-graph-kubernetes-metrics
#
- name: "kube-prometheus"
  namespace: "monitoring"
  labels:
    chart: "kube-prometheus"
    component: "monitoring"
    namespace: "monitoring"
    vendor: "coreos"
    default: "true"
  chart: "coreos-stable/kube-prometheus"
  version: "0.0.66"
  values:
    - "values/kube-prometheus.grafana.dashboards.yaml"
  set:
    - name: "global.rbacEnable"
      value: "false"

    - name: "deployExporterNode"
      value: "true"

    - name: "exporter-node.resources.limits.cpu"
      value: "10m"

    - name: "exporter-node.resources.limits.memory"
      value: "32Mi"

    - name: "exporter-node.resources.requests.cpu"
      value: "5m"

    - name: "exporter-node.resources.requests.memory"
      value: "16Mi"

    - name: "deployGrafana"
      value: "true"

    - name: "grafana.resources.limits.cpu"
      value: "50m"

    - name: "grafana.resources.limits.memory"
      value: "64Mi"

    - name: "grafana.resources.requests.cpu"
      value: "10m"

    - name: "grafana.resources.requests.memory"
      value: "64Mi"

    - name: "exporter-kube-state.resources.limits.cpu"
      value: "50m"

    - name: "exporter-kube-state.resources.limits.memory"
      value: "64Mi"

    - name: "exporter-kube-state.resources.requests.cpu"
      value: "10m"

    - name: "exporter-kube-state.resources.requests.memory"
      value: "64Mi"

    # AlertManager
    - name: "deployAlertManager"
      value: "true"

    - name: "alertmanager.paused"
      value: "false"

    - name: "alertmanager.podAntiAffinity"
      value: "soft"

    ### Optional: KUBE_PROMETHEUS_ALERT_MANAGER_REPLICA_COUNT; e.g. 4
    - name: "alertmanager.replicaCount"
      value: '{{ env "KUBE_PROMETHEUS_ALERT_MANAGER_REPLICA_COUNT" | default "4" }}'

    - name: "alertmanager.image.repository"
      value: "quay.io/prometheus/alertmanager"

    ### Optional: KUBE_PROMETHEUS_ALERT_MANAGER_IMAGE_TAG; e.g. v0.14.0
    - name: "alertmanager.image.tag"
      value: '{{ env "KUBE_PROMETHEUS_ALERT_MANAGER_IMAGE_TAG" | default "v0.14.0" }}'

    - name: "alertmanager.image.pullPolicy"
      value: "IfNotPresent"

    - name: "alertmanager.resources.limits.cpu"
      value: "10m"

    - name: "alertmanager.resources.limits.memory"
      value: "64Mi"

    - name: "alertmanager.resources.requests.cpu"
      value: "5m"

    - name: "alertmanager.resources.requests.memory"
      value: "32Mi"

    - name: "alertmanager.config.global.resolve_timeout"
      value: "5m"

    - name: "alertmanager.config.route.group_by[0]"
      value: "alertname"

    - name: "alertmanager.config.route.group_by[1]"
      value: "namespace"

    - name: "alertmanager.config.route.group_wait"
      value: "30s"

    - name: "alertmanager.config.route.group_interval"
      value: "5m"

    - name: "alertmanager.config.route.repeat_interval"
      value: "12h"

    - name: "alertmanager.config.route.receiver"
      value: "slack_general"

    - name: "alertmanager.config.route.routes[0].match.alertname"
      value: "DeadMansSwitch"

    - name: "alertmanager.config.route.routes[0].match.receiver"
      value: "null"

    - name: "alertmanager.config.receivers[0].name"
      value: "null"

    - name: "alertmanager.config.receivers[1].name"
      value: "slack_general"

    ### Required: KUBE_PROMETHEUS_ALERT_MANAGER_SLACK_WEBHOOK_URL
    - name: "alertmanager.config.receivers[1].slack_configs[0].api_url"
      value: '{{ env "KUBE_PROMETHEUS_ALERT_MANAGER_SLACK_WEBHOOK_URL" }}'

    ### Required: KUBE_PROMETHEUS_ALERT_MANAGER_SLACK_CHANNEL; e.g. #alerts-staging
    - name: "alertmanager.config.receivers[1].slack_configs[0].channel"
      value: '{{ env "KUBE_PROMETHEUS_ALERT_MANAGER_SLACK_CHANNEL" }}'

    - name: "alertmanager.config.receivers[1].slack_configs[0].send_resolved"
      value: "true"

    - name: "alertmanager.service.type"
      value: "ClusterIP"

    - name: "alertmanager.service.port"
      value: "80"

    - name: "alertmanager.ingress.enabled"
      value: "false"

    # Prometheus
    - name: "prometheus.retention"
      value: "31d"

    - name: "prometheus.routePrefix"
      value: "/"

    - name: "prometheus.config.specifiedInValues"
      value: "true"

    - name: "prometheus.rules.specifiedInValues"
      value: "true"

    - name: "prometheus.paused"
      value: "false"

    - name: "prometheus.podAntiAffinity"
      value: "soft"

    ### Optional: KUBE_PROMETHEUS_REPLICA_COUNT; e.g. 4
    - name: "prometheus.replicaCount"
      value: '{{ env "KUBE_PROMETHEUS_REPLICA_COUNT" | default "4" }}'

    - name: "prometheus.image.repository"
      value: "quay.io/prometheus/prometheus"

    ### Optional: KUBE_PROMETHEUS_IMAGE_TAG; e.g. v2.2.1
    - name: "prometheus.image.tag"
      value: '{{ env "KUBE_PROMETHEUS_IMAGE_TAG" | default "v2.2.1" }}'

    - name: "prometheus.image.pullPolicy"
      value: "IfNotPresent"

    - name: "prometheus.resources.limits.cpu"
      value: "400m"

    - name: "prometheus.resources.limits.memory"
      value: "2048Mi"

    - name: "prometheus.resources.requests.cpu"
      value: "100m"

    - name: "prometheus.resources.requests.memory"
      value: "512Mi"

    - name: "prometheus.storage.volumeClaimTemplate.spec.accessModes[0]"
      value: "ReadWrite"

    - name: "prometheus.storage.volumeClaimTemplate.spec.resources.requests.storage"
      value: "50Gi"

    - name: "prometheus.service.type"
      value: "ClusterIP"

    - name: "prometheus.service.port"
      value: "80"

    - name: "prometheus.ingress.enabled"
      value: "false"


#######################################################################################
## datadog                                                                           ##
## Datadog is a hosted infrastructure monitoring platform                            ##
#######################################################################################

#
# References:
#   - https://github.com/kubernetes/charts/tree/master/stable/datadog
#   - https://github.com/kubernetes/charts/blob/master/stable/datadog/values.yaml
#
- name: "datadog"
  namespace: "monitoring"
  labels:
    chart: "datadog"
    component: "monitoring"
    namespace: "monitoring"
    vendor: "datadog"
    default: "false"
  chart: "stable/datadog"
  version: "0.16.0"
  set:
    - name: "image.repository"
      value: "datadog/agent"

    ### Optional: DATADOG_IMAGE_TAG; e.g. 6.1.2
    - name: "image.tag"
      value: '{{ env "DATADOG_IMAGE_TAG" | default "6.1.2" }}'

    - name: "image.pullPolicy"
      value: "IfNotPresent"

    - name: "resources.limits.cpu"
      value: "256m"

    - name: "resources.limits.memory"
      value: "512Mi"

    - name: "resources.requests.cpu"
      value: "50m"

    - name: "resources.requests.memory"
      value: "64Mi"

    - name: "datadog.apiKey"
      value: '{{ env "DATADOG_API_KEY" }}'

    - name: "datadog.collectEvents"
      value: "true"

    ### Optional: DATADOG_APM_ENABLED; e.g. true
    - name: "datadog.apmEnabled"
      value: '{{ env "DATADOG_APM_ENABLED" | default "false" }}'

    - name: "rbac.create"
      value: "false"

    - name: "kube-state-metrics.rbac.create"
      value: "false"

    ### Optional: DATADOG_USE_HOST_PORT; e.g. false
    - name: "daemonset.useHostPort"
      value: '{{ env "DATADOG_USE_HOST_PORT" | default "true" }}'

    ### Optional: DATADOG_UPDATE_STRATEGY; e.g. RollingUpdate
    - name: "daemonset.updateStrategy"
      value: '{{ env "DATADOG_UPDATE_STRATEGY" | default "OnDelete" }}'

#######################################################################################
## Fluentd to datadog logs                                                           ##
## Forward logs to Datadog with fluentd                                              ##
#######################################################################################

#
# References:
#   - https://github.com/kubernetes/charts/blob/master/incubator/fluentd/
#   - https://github.com/kubernetes/charts/blob/master/incubator/fluentd/values.yaml
#   - https://github.com/cloudposse/fluentd-datadog-logs
#

- name: "fluentd-datadog-logs"
  namespace: "kube-system"
  labels:
    chart: "fluentd-kubernetes"
    component: "datadog"
    namespace: "kube-system"
    default: "false"
  chart: "cloudposse-incubator/fluentd-kubernetes"
  version: "0.2.0"
  set:
    - name: "image.repository"
      value: "cloudposse/fluentd-datadog-logs"

    - name: "image.tag"
      value: "0.1.1"

    - name: "image.pullPolicy"
      value: "Always"

    - name: "resources.limits.cpu"
      value: "50m"

    - name: "resources.limits.memory"
      value: "512Mi"

    - name: "resources.requests.cpu"
      value: "5m"

    - name: "resources.requests.memory"
      value: "256Mi"

    - name: "env.open.DATADOG_SOURCE"
      value: '{{ env "DATADOG_SOURCE" | default "k8s-staging" }}'

    - name: "env.secret.DATADOG_API_KEY"
      value: '{{ env "DATADOG_API_KEY" }}'

    - name: "configDir"
      value: "/tmp/conf"


#######################################################################################
## Fluentd to Elasticsearch logs                                                     ##
## Forward logs to Elasticsearch with fluentd                                        ##
#######################################################################################

#
# References:
#   - https://github.com/cloudposse/charts/blob/master/incubator/fluentd-kubernetes/values.yaml
#

- name: "fluentd-elasticsearch-logs"
  namespace: "kube-system"
  labels:
    chart: "fluentd-kubernetes"
    component: "elasticsearch"
    namespace: "kube-system"
    default: "false"
  chart: "cloudposse-incubator/fluentd-kubernetes"
  version: "0.2.0"
  set:
  - name: "image.repository"
    value: "fluent/fluentd-kubernetes-daemonset"

  - name: "image.tag"
    value: "v0.12.33-elasticsearch"

  - name: "image.pullPolicy"
    value: "Always"

  - name: "resources.limits.cpu"
    value: "50m"

  - name: "resources.limits.memory"
    value: "512Mi"

  - name: "resources.requests.cpu"
    value: "5m"

  - name: "resources.requests.memory"
    value: "256Mi"

  - name: "env.open.FLUENT_ELASTICSEARCH_HOST"
    value: '{{ env "ELASTICSEARCH_HOST" }}'

  - name: "env.open.FLUENT_ELASTICSEARCH_PORT"
    value: '{{ env "ELASTICSEARCH_PORT" }}'

  - name: "env.open.FLUENT_UID"
    value: "0"

  - name: "env.secret.FLUENT_ELASTICSEARCH_USER"
    value: '{{ env "ELASTICSEARCH_USER" }}'

  - name: "env.secret.FLUENT_ELASTICSEARCH_PASSWORD"
    value: '{{ env "ELASTICSEARCH_PASSWORD" }}'

  - name: "configDir"
    value: "/tmp/conf"


#######################################################################################
## heapster                                                                          ##
## Compute Resource Usage Analysis and Monitoring of Container Clusters              ##
#######################################################################################

#
# References:
#   - https://github.com/kubernetes/heapster
#   - https://github.com/kubernetes/charts/blob/master/stable/heapster/values.yaml
#
- name: "heapster"
  namespace: "kube-system"
  labels:
    chart: "heapster"
    component: "monitoring"
    namespace: "kube-system"
    vendor: "kubernetes"
    default: "true"
  chart: "stable/heapster"
  version: "0.2.10"
  set:
    - name: "replicaCount"
      value: '{{ env "HEAPSTER_REPLICA_COUNT" | default "1" }}'

    - name: "image.repository"
      value: "k8s.gcr.io/heapster"

    - name: "image.tag"
      value: '{{ env "HEAPSTER_IMAGE_TAG" | default "v1.3.0" }}'

    - name: "image.pullPolicy"
      value: "IfNotPresent"

    - name: "resources.limits.cpu"
      value: "100m"

    - name: "resources.limits.memory"
      value: "256Mi"

    - name: "resources.requests.cpu"
      value: "50m"

    - name: "resources.requests.memory"
      value: "128Mi"


#######################################################################################
## kubernetes-dashboard                                                              ##
## General-purpose web UI for Kubernetes clusters                                    ##
#######################################################################################

#
# References:
#   - https://github.com/kubernetes/dashboard
#   - https://github.com/kubernetes/charts/tree/master/stable/kubernetes-dashboard
#
- name: "kubernetes-dashboard"
  namespace: "kube-system"
  labels:
    chart: "kubernetes-dashboard"
    component: "monitoring"
    namespace: "kube-system"
    vendor: "kubernetes"
    default: "true"
  chart: "stable/kubernetes-dashboard"
  version: "0.6.7"
  set:
    - name: "image.repository"
      value: "k8s.gcr.io/kubernetes-dashboard-amd64"

    - name: "image.tag"
      value: '{{ env "KUBERNETES_DASHBOARD_IMAGE_TAG" | default "v1.8.3" }}'

    - name: "image.pullPolicy"
      value: "IfNotPresent"

    - name: "resources.limits.cpu"
      value: "100m"

    - name: "resources.limits.memory"

      value: "100Mi"

    - name: "resources.requests.cpu"
      value: "50m"

    - name: "resources.requests.memory"
      value: "50Mi"

    - name: "rbac.create"
      value: "false"

    - name: "serviceAccount.create"
      value: "true"



#######################################################################################
## portal                                                                            ##
## Portal for Kubernetes services                                                    ##
#######################################################################################

#
# References:
#   - https://github.com/cloudposse/charts/tree/master/incubator/portal
#   - https://github.com/cloudposse/charts/blob/master/incubator/portal/values.yaml
#
- name: "portal"
  namespace: "monitoring"
  labels:
    chart: "portal"
    component: "monitoring"
    namespace: "monitoring"
    vendor: "cloudposse"
    default: "true"
  chart: "cloudposse-incubator/portal"
  version: "0.1.0"
  values:
    - "values/portal.yaml"
    - "values/portal.backends.yaml"
  set:
      ## backends
    - name: "backends.dashboard.name"
      value: '{{ env "PORTAL_BACKEND_K8S_DASHBOARD_NAME" | default "Kubernetes" }}'
    - name: "backends.dashboard.endpoint"
      value: '{{ env "PORTAL_BACKEND_K8S_DASHBOARD_ENDPOINT" | default "https://kubernetes-dashboard.kube-system:443" }}'
    - name: "backends.dashboard.external"
      value: "false"

    - name: "backends.grafana.name"
      value: '{{ env "PORTAL_BACKEND_GRAFANA_NAME" | default "Grafana" }}'
    - name: "backends.grafana.endpoint"
      value: '{{ env "PORTAL_BACKEND_GRAFANA_ENDPOINT" | default "http://kube-prometheus-grafana.monitoring:80" }}'
    - name: "backends.grafana.external"
      value: "false"

    - name: "backends.alerts.name"
      value: '{{ env "PORTAL_BACKEND_ALERTS_NAME" | default "Alerts" }}'
    - name: "backends.alerts.endpoint"
      value: '{{ env "PORTAL_BACKEND_ALERTS_ENDPOINT" | default "http://kube-prometheus-alertmanager.monitoring:9093" }}'
    - name: "backends.alerts.external"
      value: "false"

    - name: "backends.prometheus.name"
      value: '{{ env "PORTAL_BACKEND_PROMETHEUS_NAME" | default "Prometheus" }}'
    - name: "backends.prometheus.endpoint"
      value: '{{ env "PORTAL_BACKEND_PROMETHEUS_ENDPOINT" | default "http://kube-prometheus-prometheus.monitoring:9090" }}'
    - name: "backends.prometheus.external"
      value: "false"

    - name: "backends.docs.name"
      value: '{{ env "PORTAL_BACKEND_DOCS_NAME" | default "Docs" }}'
    - name: "backends.docs.endpoint"
      value: '{{ env "PORTAL_BACKEND_DOCS_ENDPOINT" | default "https://docs.cloudposse.com/" }}'
    - name: "backends.docs.external"
      value: "true"

    - name: "config.title"
      value: '{{ env "PORTAL_TITLE" }}'
    - name: "config.brand"
      value: '{{ env "PORTAL_BRAND" }}'
    - name: "config.basehost"
      value: '{{ env "PORTAL_HOSTNAME" }}'
    - name: "config.image.favicon"
      value: '{{ env "PORTAL_BRAND_IMAGE_FAVICON_URL" | default "https://cloudposse.com/wp-content/uploads/sites/29/2016/04/favicon-152.png" }}'
    - name: "config.image.url"
      value: '{{ env "PORTAL_BRAND_IMAGE_URL" | default "https://raw.githubusercontent.com/cloudposse/helm-chart-scaffolding/master/logo.png" }}'
    - name: "config.image.width"
      value: '{{ env "PORTAL_BRAND_IMAGE_WIDTH" | default "35" }}'

    ## dashboard
    - name: "dashboard.replicaCount"
      value: '{{ env "PORTAL_DASHBOARD_REPLICA_COUNT" | default "2" }}'

    - name: "dashboard.image.repository"
      value: "nginx"

    - name: "dashboard.image.tag"
      value: '{{ env "PORTAL_DASHBOARD_IMAGE_TAG" | default "latest" }}'

    - name: "dashboard.image.pullPolicy"
      value: "Always"

    - name: "dashboard.service.externalPort"
      value: "80"

    - name: "dashboard.service.internalPort"
      value: "80"

    - name: "dashboard.resources.limits.cpu"
      value: "5m"

    - name: "dashboard.resources.limits.memory"
      value: "16Mi"

    - name: "dashboard.resources.requests.cpu"
      value: "3m"

    - name: "dashboard.resources.requests.memory"
      value: "8Mi"

    ## proxy
    - name: "proxy.enabled"
      value: "true"

    - name: "proxy.replicaCount"
      value: '{{ env "PORTAL_PROXY_REPLICA_COUNT" | default "2" }}'

    - name: "proxy.image.repository"
      value: "traefik"

    - name: "proxy.image.tag"
      value: '{{ env "PORTAL_PROXY_IMAGE_TAG" | default "1.5.4" }}'

    - name: "proxy.image.pullPolicy"
      value: "Always"

    - name: "proxy.service.externalPort"
      value: "80"

    - name: "proxy.service.internalPort"
      value: "80"

    - name: "proxy.resources.limits.cpu"
      value: "5m"

    - name: "proxy.resources.limits.memory"
      value: "64Mi"

    - name: "proxy.resources.requests.cpu"
      value: "3m"

    - name: "proxy.resources.requests.memory"
      value: "32Mi"

    ## oauth2-proxy
    - name: "oauth2-proxy.app.useSSL"
      value: "false"

    - name: "oauth2-proxy.app.upstreams[0]"
      value: "file:///dev/null"

    - name: "oauth2-proxy.app.provider"
      value: "github"

    - name: "oauth2-proxy.app.clientID"
      value: '{{ env "PORTAL_OAUTH2_PROXY_GITHUB_CLIENT_ID" }}'

    - name: "oauth2-proxy.app.clientSecret"
      value: '{{ env "PORTAL_OAUTH2_PROXY_GITHUB_CLIENT_SECRET" }}'

    - name: "oauth2-proxy.app.githubOrg"
      value: '{{ env "PORTAL_OAUTH2_PROXY_GITHUB_ORGANIZATION" }}'

    - name: "oauth2-proxy.app.githubTeam"
      value: '{{ env "PORTAL_OAUTH2_PROXY_GITHUB_TEAM" }}'

    - name: "oauth2-proxy.app.requestLogging"
      value: "false"

    - name: "oauth2-proxy.app.passAccessToken"
      value: "false"

    - name: "oauth2-proxy.app.passBasicAuth"
      value: "false"

    - name: "oauth2-proxy.app.passHostHeader"
      value: "true"

    - name: "oauth2-proxy.app.cookieName"
      value: '{{ env "PORTAL_OAUTH2_PROXY_COOKIE_NAME" }}'

    - name: "oauth2-proxy.app.cookieSecret"
      value: '{{ env "PORTAL_OAUTH2_PROXY_COOKIE_SECRET" }}'

    - name: "oauth2-proxy.app.cookieDomain"
      value: '.{{ env "PORTAL_HOSTNAME" }}'

    - name: "oauth2-proxy.app.cookieSecure"
      value: "true"

    - name: "oauth2-proxy.app.cookieHttponly"
      value: "false"

    - name: "oauth2-proxy.app.replicaCount"
      value: '{{ env "PORTAL_OAUTH2_PROXY_REPLICA_COUNT" | default "2" }}'

    - name: "oauth2-proxy.app.image.repository"
      value: "cloudposse/oauth2-proxy"

    - name: "oauth2-proxy.app.image.tag"
      value: '{{ env "PORTAL_OAUTH2_PROXY_IMAGE_TAG" | default "2.2" }}'

    - name: "oauth2-proxy.app.image.pullPolicy"
      value: "Always"

    - name: "oauth2-proxy.app.resources.limits.cpu"
      value: "10m"

    - name: "oauth2-proxy.app.resources.limits.memory"
      value: "16Mi"

    - name: "oauth2-proxy.app.resources.requests.cpu"
      value: "5m"

    - name: "oauth2-proxy.app.resources.requests.memory"
      value: "8Mi"

    ## Ingress
    - name: "ingress.enabled"
      value: "true"

    - name: "ingress.dns.enabled"
      value: "false"

    ### Optional: PORTAL_INGRESS_TLS_ENABLED; e.g. false
    - name: "ingress.tls.enabled"
      value: '{{ env "PORTAL_INGRESS_TLS_ENABLED" | default "true" }}'

    - name: "ingress.annotations.kubernetes\\.io/ingress\\.class"
      value: "nginx"

    # FIXME: this is blocked by https://github.com/roboll/helmfile/issues/119
    #- name: "ingress.annotations.kubernetes\\.io/tls-acme"
    #  value: "true"

    ### Required: PORTAL_INGRESS; e.g. ingress.us-west-2.staging.cloudposse.co
    - name: "ingress.annotations.external-dns\\.alpha\\.kubernetes\\.io/target"
      value: '{{ env "PORTAL_INGRESS" }}'

    # DNS TTL for PORTAL_HOSTNAME; e.g. 60
    # FIXME: this is blocked by https://github.com/roboll/helmfile/issues/119
    #- name: "ingress.annotations.external-dns\\.alpha\\.kubernetes\\.io/ttl"
    #  value: "60"


#######################################################################################
## Kibana                                                                            ##
## Open source, browser-based analytics and search dashboard for Elasticsearch       ##
#######################################################################################

#
# References:
#   - https://github.com/helm/charts/blob/master/stable/kibana/values.yaml
#
- name: "kibana"
  namespace: "monitoring"
  labels:
    chart: "kibana"
    component: "monitoring"
    namespace: "monitoring"
    vendor: "kubernetes-helm"
    default: "false"
  chart: "stable/kibana"
  version: "0.6.0"
  values:
    - replicaCount: {{ env "KIBANA_REPLICA_COUNT" | default 1 }}
    - image:
        repository: "docker.elastic.co/kibana/kibana-oss"
        pullPolicy: "IfNotPresent"
    - service:
        type: ClusterIP
        externalPort: 443
        internalPort: {{ env "KIBANA_SERVER_PORT" | default "5601" }}
        annotations:
          iam.amazonaws.com/role: {{ env "ELASTICSEARCH_IAM_ROLE" }}
        labels:
          # Show service URL in `kubectl cluster-info`
          kubernetes.io/cluster-service: "true"
    - resources:
        limits:
          cpu: 500m
          memory: 1024Mi
        requests:
          cpu: 200m
          memory: 512Mi
    - ingress:
        enabled: "true"
        annotations:
          kubernetes.io/ingress.class: "nginx"
          kubernetes.io/tls-acme: "true"
          external-dns.alpha.kubernetes.io/ttl: "60"
          external-dns.alpha.kubernetes.io/target: {{ env "KIBANA_INGRESS" }}
          external-dns.alpha.kubernetes.io/hostname: {{ env "KIBANA_HOSTNAME" }}
        hosts:
        - {{ env "KIBANA_HOSTNAME" }}
        tls:
        - secretName: {{ env "KIBANA_SECRET_NAME" | default "kibana-server-tls" }}
          hosts:
          - {{ env "KIBANA_HOSTNAME" }}
    - files:
        kibana.yml:
          ## Default Kibana configuration from kibana-docker.
          server.name: kibana
          server.host: "localhost"
          elasticsearch.url: {{ env "ELASTICSEARCH_HOST" }}:{{ env "ELASTICSEARCH_PORT" }}

          ## Custom config properties
          ## Ref: https://www.elastic.co/guide/en/kibana/current/settings.html
          server.port: {{ env "KIBANA_SERVER_PORT" | default "5601" }}
          logging.verbose: "false"
          server.defaultRoute: "/app/kibana"
    - env:
      # All Kibana configuration options are adjustable via env vars.
      # To adjust a config option to an env var uppercase + replace `.` with `_`
      # Ref: https://www.elastic.co/guide/en/kibana/current/settings.html
      ELASTICSEARCH_URL: {{ env "ELASTICSEARCH_HOST" }}:{{ env "ELASTICSEARCH_PORT" }}
      SERVER_PORT: {{ env "KIBANA_SERVER_PORT" | default "5601" }}
