#!/bin/bash

# We expect AWS_DEFAULT_SHORT_REGION was set in Dockerfile, and if not there,
# then in aws.sh, but just in case...
AWS_DEFAULT_SHORT_REGION=${AWS_DEFAULT_SHORT_REGION:-$(aws-region --${AWS_REGION_ABBREVIATION_TYPE} ${AWS_DEFAULT_REGION:-us-west-2})}

function usage() {
	cat >&2 <<'EOF'
Usage:
  eks-update-kubeconfig <cluster-short-name> [role-short-name]
  eks-update-kubeconfig set-kubeconfig <cluster-short-name> [role-short-name]
  eks-update-kubeconfig off

  With <cluster-short-name> updates the kubecfg file for the cluster with that short name (e.g. "corp")
  using the role provided or the $EKS_DEFAULT_AWS_ROLE (defaults to "admin") if none specified.

  With "set-kubeconfig" outputs the fully-qualified name of the file generated by this command.

  With "off", deletes the currently active kubecfg file.

  If it is desired to have single kubeconfig file with all contexts, as opposed to a separate kubeconfig file for each
  context, override the EKS_KUBECONFIG_PATTERN environment variable such that it points to a single file, for example
  /config/.kube/config. Afterwards, a tool such as kubectx can be used to switch between contexts.

  NOTE: This tool assumes you are using Cloud Posse's standard naming conventions:
  * Cluster name "uw2-corp" expands to "${NAMESPACE}-uw2-corp-eks-cluster"
  * Role name "admin" expands to "${NAMESPACE}-gbl-corp-admin"

  NOTE: This tool supports using an optional "tenant" label (see: https://github.com/cloudposse/terraform-null-label):
  * If <cluster-short-name> has 2 hyphens, the part before the first hyphen is considered the tenant
  * Cluster name "acme-uw2-corp" expands to "${NAMESPACE}-acme-uw2-corp-eks-cluster"
  * Role name "admin" expands to "${NAMESPACE}-acme-gbl-corp-admin"

EOF
}

function profile_name() {
	local profile_arg="${2:-${EKS_DEFAULT_AWS_ROLE-admin}}"
	if [[ $TENANT_LABEL_ENABLED == true ]]; then
		printf "%s" "${NAMESPACE}-${1%%-*}-gbl-${1##*-}-${profile_arg##*-}"
	else
		printf "%s" "${NAMESPACE}-gbl-${1#*-}-${profile_arg##*-}"
	fi
}

function file_name() {
	KUBECONFIG_DIR=$(dirname ${KUBECONFIG:-/dev/shm/kubecfg})
	EKS_KUBECONFIG_PATTERN="${EKS_KUBECONFIG_PATTERN:-${KUBECONFIG_DIR}/kubecfg.%s-%s}"
	local profile=$(profile_name $1 $2)
	printf "${EKS_KUBECONFIG_PATTERN}" "${NAMESPACE:+${NAMESPACE}-}$1" "${profile##*-}"
}

function short_region() {
	if [[ $1 =~ ^[a-z]+$ ]]; then
		echo ${AWS_DEFAULT_SHORT_REGION}
	else
		if [[ $TENANT_LABEL_ENABLED == true ]]; then
			printf "%s" "$1" | cut -f2 -d-
		else
			printf "%s" "$1" | cut -f1 -d-
		fi
	fi
}

function region() {
	aws-region $(short_region $1) 2>/dev/null || {
		red could not find region in "$1" >&2
		echo none
		return 1
	}
}

function red() {
	echo "$(tput setaf 1)$*$(tput sgr0)"
}

main() {
	if (($# == 0)); then
		usage
		return 1
	fi
	if [[ $KUBECONFIG =~ ":" ]]; then
		red "$0 requires that KUBECONFIG point to a single file, not a set of directories" >&2
		return 9
	fi
	if [[ $1 == "off" ]]; then
		if [[ -n $KUBECONFIG ]] && [[ -f $KUBECONFIG ]]; then
			rm -f $KUBECONFIG
		fi
		return 0
	fi
	local role
	if [[ $1 == "set-kubeconfig" ]]; then
		role="$3"
	else
		role="$2"
	fi
	if [[ -z $role ]]; then
		role="${EKS_DEFAULT_AWS_ROLE:-admin}"
	fi
	if [[ $1 == "set-kubeconfig" ]]; then
		file_name $2 $role
		return 0
	fi
	local cluster
	cluster="$1"
	if [[ -z "$TENANT_LABEL_ENABLED" ]]; then
		if [[ $cluster =~ ^[^-]+-[^-]+-[^-]+$ ]]; then
			TENANT_LABEL_ENABLED=true
		elif [[ -n "$TENANT" ]] && [[ $cluster =~ ^[^-]+-[^-]+$ ]]; then
			TENANT_LABEL_ENABLED=true
			cluster="${TENANT}-${cluster}"
		fi
	fi

	local kubecfg="$(file_name "${cluster}" $role)"
	EKS_CLUSTER_NAME_PATTERN="${EKS_CLUSTER_NAME_PATTERN:-${NAMESPACE:+${NAMESPACE}-}%s-eks-cluster}"
	aws --profile $(profile_name "${cluster}" $role) --region $(region "${cluster}") eks update-kubeconfig --name=$(printf "$EKS_CLUSTER_NAME_PATTERN" "${cluster}") --kubeconfig="$kubecfg"
	chmod 600 "$kubecfg"
}

main "$@"
