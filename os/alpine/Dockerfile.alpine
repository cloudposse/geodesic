# https://alpinelinux.org/
ARG ALPINE_VERSION=3.18.5
# https://cloud.google.com/sdk/docs/release-notes
ARG GOOGLE_CLOUD_SDK_VERSION=455.0.0
# https://github.com/ahmetb/kubectx/releases
ARG KUBECTX_COMPLETION_VERSION=0.9.5
# https://github.com/jonmosco/kube-ps1/releases
ARG KUBE_PS1_VERSION=0.8.0
# https://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager-working-with-install-plugin.html#plugin-version-history
ARG SESSION_MANAGER_PLUGIN_VERSION=latest
# https://bindfs.org/downloads/
ARG BINDFS_VERSION=1.17.6

# Helm plugins:
# https://github.com/databus23/helm-diff/releases
ARG HELM_DIFF_VERSION=3.8.1
# https://github.com/aslafy-z/helm-git/releases
# We had issues with helm-diff 3.1.3 + helm-git 0.9.0,
# previous workaround was to pin helm-git to version 0.8.1.
# We expect this has been fixed now with helm-diff 3.3.2 + helm-git 0.11.1
ARG HELM_GIT_VERSION=0.15.1

#
# Python Dependencies
#
FROM alpine:$ALPINE_VERSION as python

RUN sed -i 's|http://dl-cdn.alpinelinux.org|https://alpine.global.ssl.fastly.net|g' /etc/apk/repositories
# The PyYAML Python package requires "Cython" to build as of 2022-05-15
RUN apk add --update -U python3 python3-dev py3-pip libffi-dev gcc linux-headers musl-dev openssl-dev make

## Note:
# To install aws-gogle-auth:
# - add `aws-google-auth==0.0.34` to requirements.txt
# - add these libraries here (python build time)
#   - libjpeg-turbo-dev libxml2-dev libxslt-dev
# - add these libraries to packages.txt
#   - libjpeg-turbo
#   - libxml2
#   - libxslt

COPY requirements.txt /requirements.txt

# The cryptography package has to be built specially for Alpine before it can be installed,
# so we have to install it on the "host" (which builds a wheel) before installing for the distribution.
# As of 2022-05-15 PyYAML also requires the installation of Cython for some reason, although
# it does not appear to actually use it. Seems like a build tool configuration issue,
# so we were not pinning Cython or putting it in requirements.txt because Debian does not need it.
# As of 2023-07-21, we must pin Cython<3 for PyYaml <6
# See https://github.com/yaml/pyyaml/issues/724
# However, as of AWS CLI v1.29.4, we can use PyYaml 6.0.1, which solves the problem, and lets us remove Cython.
RUN python3 -m pip install --upgrade pip setuptools wheel && \
    pip install $(grep cryptography /requirements.txt) && \
    pip install -r /requirements.txt --ignore-installed --prefix=/dist --no-build-isolation --no-warn-script-location

### While we have gcc installed, we take advantage of that and build bindfs
### We used to use fuse (FUSE 2) rather than fuse3 for consistency with Debian,
### but Debian upgraded to Fuse 3 with Debian 11 ("bullseye"), so we are now using Fuse 3.
RUN apk add curl fuse3 fuse3-dev
ARG BINDFS_VERSION
RUN curl -qOsSL https://bindfs.org/downloads/bindfs-${BINDFS_VERSION}.tar.gz
RUN tar zxf bindfs-${BINDFS_VERSION}.tar.gz && cd bindfs-${BINDFS_VERSION}/ && \
    ./configure && make && make install

#
# Get AWS session-manager-plugin from Ubuntu package
#
FROM ubuntu:22.04 as session-manager-plugin

ARG SESSION_MANAGER_PLUGIN_VERSION
RUN apt-get update \
    && apt-get install -y curl \
    && curl -Lo "session-manager-plugin.deb" "https://s3.amazonaws.com/session-manager-downloads/plugin/${SESSION_MANAGER_PLUGIN_VERSION}/ubuntu_64bit/session-manager-plugin.deb" \
    && dpkg -i "session-manager-plugin.deb" \
    && /usr/local/sessionmanagerplugin/bin/session-manager-plugin  --version

#
# Google Cloud SDK
#
FROM google/cloud-sdk:$GOOGLE_CLOUD_SDK_VERSION-alpine as google-cloud-sdk

#
# Geodesic base image
#
FROM alpine:$ALPINE_VERSION

ARG VERSION
ENV GEODESIC_VERSION=$VERSION
ENV GEODESIC_OS=alpine

# Set XDG environment variables per https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html
# This is not a "multi-user" system, so we'll use special directories under
# - /etc as the global configuration dir instead of default $HOME/.config
# - /usr/share as the global data dir instead of default $HOME/.local/share
# - /tmp as the global cache dir instead of default  $HOME/.cache
# This allows daemon/server users like Atlantis to use the same
# configuration as the root user, which is usually what we want.
# If the daemon wants isolation, it can unset the variables
# or set them to something else.
# We leave the runtime dir unset/default since that is specifically
# required to be owned by the current user.
# Read more: <https://wiki.archlinux.org/index.php/XDG_Base_Directory>
ENV XDG_DATA_HOME=/usr/share/xdg_data_home
ENV XDG_CONFIG_HOME=/etc/xdg_config_home
ENV XDG_CACHE_HOME=/var/cache/xdg_cache_home
RUN for dir in $XDG_DATA_HOME $XDG_CONFIG_HOME $XDG_CACHE_HOME; do \
	mkdir -p $dir; chmod 777 $dir; done

ENV BANNER "geodesic"

ENV MOTD_URL=http://geodesic.sh/motd
ENV HOME=/conf
ENV KOPS_CLUSTER_NAME=example.foo.bar

# Install all packages as root
USER root

# install the cloudposse alpine repository
RUN apk add --no-cache bash curl && \
  curl -1sLf \
  'https://dl.cloudsmith.io/public/cloudposse/packages/setup.alpine.sh' \
  | bash && \
  printf "@cloudposse %s\n\n" "$(grep -h -v '^[@#]' /etc/apk/repositories | grep -F "public/cloudposse/packages" | head -1)" \
  >> /etc/apk/repositories

# Install the @community repo tag (community repo is already installed, but not tagged as @community)
RUN printf "@community %s\n" "$(grep -E 'alpine/v[^/]+/community' /etc/apk/repositories | head -1)" >> /etc/apk/repositories

# Install the @testing repo tag
RUN echo "@testing https://dl-cdn.alpinelinux.org/alpine/edge/testing" >> /etc/apk/repositories


##########################################################################################
# See Dockerfile.options for how to install `glibc` for greater compatibility, including #
# being able to use AWS CLI v2. You would install `glibc` and `libc6-compat` here, then  #
# install the packages below, then the Python stuff, then move AWS CLI v1 aside, and     #
# then install the AWS CLI v2                                                            #
##########################################################################################

# Install alpine package manifest
COPY packages.txt os/alpine/packages-alpine.txt /etc/apk/

## Here is where we would copy in the repo checksum in an attempt to ensure updates bust the Docker build cache

RUN apk add --update $(grep -h -v '^#' /etc/apk/packages.txt /etc/apk/packages-alpine.txt) && \
    mkdir -p /etc/bash_completion.d/ /etc/profile.d/ /conf && \
    touch /conf/.gitconfig

# Here is where we would confirm that the package repo checksum is what we expect (not mismatched due to Docker layer cache)

RUN echo "net.ipv6.conf.all.disable_ipv6=0" > /etc/sysctl.d/00-ipv6.conf

# Disable vim from reading a swapfile (incompatible with goofys)
RUN echo 'set noswapfile' >> /etc/vim/vimrc

WORKDIR /tmp

# Copy python dependencies
COPY --from=python /dist/ /usr/

# Install bindfs
COPY --from=python /usr/local/bin/bindfs /usr/local/bin/bindfs

# Install AWS CLI session manager plugin
COPY --from=session-manager-plugin /usr/local/sessionmanagerplugin/bin/session-manager-plugin /usr/local/bin/session-manager-plugin

#
# Install Google Cloud SDK
#
ENV CLOUDSDK_CONFIG=/localhost/.config/gcloud/

COPY --from=google-cloud-sdk /google-cloud-sdk/ /usr/local/google-cloud-sdk/

RUN ln -s /usr/local/google-cloud-sdk/completion.bash.inc /etc/bash_completion.d/gcloud.sh && \
    ln -s /usr/local/google-cloud-sdk/bin/gcloud /usr/local/bin/ && \
    ln -s /usr/local/google-cloud-sdk/bin/gsutil /usr/local/bin/ && \
    ln -s /usr/local/google-cloud-sdk/bin/bq /usr/local/bin/

# gcloud config writes successful status updates to stderr, but we want to preserve
# stderr for real errors in need of action.
RUN { gcloud config set core/disable_usage_reporting true --installation && \
      gcloud config set component_manager/disable_update_check true --installation && \
      gcloud config set metrics/environment github_docker_image --installation; } 2>&1

# Explicitly set  KUBECONFIG to enable kube_ps1 prompt
ENV KUBECONFIG=/conf/.kube/config
# Install an empty kubeconfig to suppress some warnings
COPY rootfs/conf/.kube/config /conf/.kube/config
# Set mode on kubeconfig to suppress some warnings while installing tools
RUN chmod 600 $KUBECONFIG

#
# Install kubectl
#
# Set KUBERNETES_VERSION and KOPS_BASE_IMAGE in /conf/kops/kops.envrc
#
RUN kubectl completion bash > /etc/bash_completion.d/kubectl.sh
ARG KUBECTX_COMPLETION_VERSION
ADD https://raw.githubusercontent.com/ahmetb/kubectx/v${KUBECTX_COMPLETION_VERSION}/completion/kubens.bash /etc/bash_completion.d/kubens.sh
ADD https://raw.githubusercontent.com/ahmetb/kubectx/v${KUBECTX_COMPLETION_VERSION}/completion/kubectx.bash /etc/bash_completion.d/kubectx.sh
#
# Install fancy Kube PS1 Prompt
#
ARG KUBE_PS1_VERSION
ADD https://raw.githubusercontent.com/jonmosco/kube-ps1/v${KUBE_PS1_VERSION}/kube-ps1.sh /etc/profile.d/prompt:kube-ps1.sh

RUN chmod 755 /etc/bash_completion.d/kubens.sh /etc/bash_completion.d/kubectx.sh /etc/profile.d/prompt:kube-ps1.sh

#
# Install helm (helm itself handled via packages.txt)
#

############# End of Helm 2 support ################################
# We no longer install helm2. If you want to install it yourself, copy and uncomment the following:
#
# helm version 2 config
#    ENV HELM_HOME /var/lib/helm
#    ENV HELM_VALUES_PATH=${SECRETS_PATH}/helm/values
#
#    RUN helm2 completion bash > /etc/bash_completion.d/helm2.sh \
#        && mkdir -p ${HELM_HOME} \
#        && helm2 init --client-only \
#        && mkdir -p ${HELM_HOME}/plugins
#
#    # Enable Atlantis to use helm 2
#    RUN chmod -R a+rwX ${HELM_HOME}
#
#   ARG HELM_HELM_2TO3_VERSION=0.10.0
#   RUN helm3 plugin install https://github.com/helm/helm-2to3 --version ${HELM_HELM_2TO3_VERSION}
#
############# End of Helm 2 support ################################

#
# Install minimal helm plugins
#

ARG HELM_DIFF_VERSION
ARG HELM_GIT_VERSION

RUN helm3 plugin install https://github.com/databus23/helm-diff.git --version v${HELM_DIFF_VERSION} \
    && helm3 plugin install https://github.com/aslafy-z/helm-git.git --version ${HELM_GIT_VERSION} \
    && rm -rf $XDG_CACHE_HOME/helm

# helm version 3 uses XDG variables set above.
# XDG directory permissions updated at end of installs.
# See https://helm.sh/docs/faq/#xdg-base-directory-support

#
# We no longer install kops or defaults. See https://github.com/cloudposse/geodesic/blob/master/Dockerfile.options
# for example settings you can add to your own Dockerfile, or see what we used to set
# here: https://github.com/cloudposse/geodesic/blob/a7a47a0d3ed558e0f5d1116291b2f2f3aa1a1b97/Dockerfile#L123-L155
#

#
# Configure host AWS configuration to be available from inside Docker image
#
# AWS_DATA_PATH is a PATH-like variable for configuring the AWS botocore library to
# load additional modules. Do not set it. ENV AWS_DATA_PATH=/localhost/.aws
ARG GEODESIC_AWS_HOME=/localhost/.aws
ENV AWS_CONFIG_FILE=${GEODESIC_AWS_HOME}/config
ENV AWS_SHARED_CREDENTIALS_FILE=${GEODESIC_AWS_HOME}/credentials
# Region abbreviation types are "fixed" (always 3 chars), "short" (4-5 chars), or "long" (the full AWS string)
# See https://github.com/cloudposse/terraform-aws-utils#introduction
ENV AWS_REGION_ABBREVIATION_TYPE=fixed

#
# Support for aws-vault (not related to HashiCorp Vault) is deprecated
# in favor of Leapp.  https://leapp.cloud
#
# ENV AWS_VAULT_ENABLED=false
# ENV AWS_VAULT_SERVER_ENABLED=false
# ENV AWS_VAULT_BACKEND=file
# ENV AWS_VAULT_ASSUME_ROLE_TTL=1h
# ENV AWS_VAULT_SESSION_TTL=12h
# ENV AWS_VAULT_FILE_PASSPHRASE=

#
# Support for aws-okta is deprecated
# in favor of Leapp.  https://leapp.cloud
#
# ENV AWS_OKTA_ENABLED=false

#
# Shell customization
#
# options for `less`. `R` allows ANSI color codes to be displayed while stripping out
# other control codes that can cause `less` to mess up the screen formatting
ENV LESS=R
# MANOPT=--no-hyphenation disables hyphenation for man pages, which is generally preferable
# for the man pages in Geodesic to preserve the ability to copy and paste code.
ENV MANOPT=--no-hyphenation
# Support for using an SSH key file on the host. No longer favored now that
# Docker supports forwarding SSH_AUTH_SOCK, but retained for backward compatibility.
# See rootfs/etc/profile.d/ssh-agent.sh
ENV SSH_AGENT_CONFIG=/var/tmp/.ssh-agent

# Set a default terminal to "dumb" (headless) to make `tput` happy when running scripts.
# When we launch Geodesic for interactive use, we forward the host value of `TERM`
ENV TERM=dumb

# Our older Geodesic configurations relied on `direnv`, which we no longer recommend,
# preferring YAML configuration files instead.
ENV DIRENV_ENABLED=false
# Our older Geodesic configuration uses multiple Makefiles, like Makefile.tasks
# and depends on setting
# ENV MAKE_INCLUDES="Makefile Makefile.*"
# but that setting causes problems in other situations, so we no longer set it by default.
# We encourage you to use https://github.com/cloudposse/atmos instead of `make` for running commands.
# If you are using (and therefore enable) `direnv`, consider the advantage
# of using `direnv` to set MAKE_INCLUDES, which is that it will only set
# it for trusted directories under `/conf` and therefore it will not affect
# `make` outside of this directory tree.

# Reduce `make` verbosity
ENV MAKEFLAGS="--no-print-directory"

# Install "root" filesystem
COPY rootfs/ /
COPY os/alpine/rootfs/ /

# Install documentation
COPY docs/ /usr/share/docs/

# Build man pages
RUN /usr/local/bin/docs update

# Make sure that "user specific" directories we are sharing
# are in fact available to all users
RUN for dir in $XDG_DATA_HOME $XDG_CONFIG_HOME $XDG_CACHE_HOME; do \
	chmod -R a+rwX $dir; done

WORKDIR /conf

ENTRYPOINT ["/bin/bash"]
CMD ["-c", "boot"]

ARG DEV_VERSION
ENV GEODESIC_DEV_VERSION=$DEV_VERSION
ENV GEODESIC_VERSION="${GEODESIC_VERSION}${GEODESIC_DEV_VERSION:+ (${GEODESIC_DEV_VERSION})}"
